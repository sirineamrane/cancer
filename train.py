import os
import hydra
from omegaconf import DictConfig, OmegaConf


@hydra.main(version_base=None, config_path="conf", config_name="config")
def main(cfg: DictConfig):
    print("=== ğŸš€ TEST HYDRA - CANCER CLASSIFICATION ===\n")

    # 1ï¸âƒ£ Afficher toute la configuration actuelle
    print("ğŸ“˜ Configuration complÃ¨te :")
    print(OmegaConf.to_yaml(cfg))

    # 2ï¸âƒ£ AccÃ©der aux paramÃ¨tres principaux
    print("\n--- ParamÃ¨tres principaux ---")
    print(f"ğŸ§  ModÃ¨le        : {cfg.model.name}")
    print(f"âš™ï¸  Optimiseur    : {cfg.optimizer.name}")
    print(f"ğŸ“Š Dataset       : {cfg.dataset.name}")
    print(f"ğŸ“ Chemin dataset: {cfg.dataset.path}")
    print(f"ğŸ” Ã‰poques       : {cfg.training.epochs}")
    print(f"ğŸ“¦ Batch size    : {cfg.training.batch_size}")

    # 3ï¸âƒ£ VÃ©rifier que le dataset est accessible
    data_path = cfg.dataset.path
    if os.path.exists(data_path):
        files = os.listdir(data_path)
        print(f"\nâœ… Dataset accessible ({len(files)} fichiers trouvÃ©s)")
        print("Exemple de contenu :", files[:5])
    else:
        print("\nâŒ ERREUR : le chemin du dataset n'existe pas !")

    # 4ï¸âƒ£ Exemple dâ€™utilisation des hyperparamÃ¨tres
    print(f"\nğŸ”§ EntraÃ®nement simulÃ© avec lr={cfg.optimizer.lr} pendant {cfg.training.epochs} Ã©poques...")
    print("â¡ï¸  (ici tu pourrais appeler ta vraie fonction d'entraÃ®nement PyTorch)")

    print("\nâœ… Test Hydra terminÃ© avec succÃ¨s !")


if __name__ == "__main__":
    main()

